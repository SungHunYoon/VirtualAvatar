import os
from openai import AsyncOpenAI
from dotenv import load_dotenv
from queue import Queue
from threading import Thread
import asyncio
from tts import speak_stream

load_dotenv()
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

tts_queue = Queue()

def tts_worker():
    asyncio.set_event_loop(asyncio.new_event_loop())
    loop = asyncio.get_event_loop()
    while True:
        text = tts_queue.get()
        if text is None:
            break
        if text.strip():
            try:
                loop.run_until_complete(speak_stream(text))
            except RuntimeError as e:
                print(f"[TTS Error] {e}")

Thread(target=tts_worker, daemon=True).start()

async def query_gpt_stream(prompt):
    print("ğŸ§  GPT ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘")
    stream = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ ë¹„ì„œì•¼. ì§§ê³  ê°„ë‹¨í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜"},
            {"role": "user", "content": prompt}
        ],
        stream=True,
    )

    buffer = ""
    async for chunk in stream:
        if chunk.choices[0].delta.content:
            piece = chunk.choices[0].delta.content
            print(piece, end="", flush=True)
            buffer += piece

            if any(p in piece for p in ".!?") or len(buffer) > 20:
                tts_queue.put(buffer.strip())
                buffer = ""

    if buffer.strip():  # ë§ˆì§€ë§‰ ë‚¨ì€ ë‚´ìš©ë„ ì²˜ë¦¬
        tts_queue.put(buffer.strip())

    print("\nğŸ§  GPT ì‘ë‹µ ì™„ë£Œ")

def shutdown_tts():
    tts_queue.put(None)
