import os
import asyncio
from openai import AsyncOpenAI
from dotenv import load_dotenv
from queue import Queue
from threading import Thread
from tts import speak_stream

load_dotenv()
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

tts_queue = Queue()
history = []
summary = ""
MAX_HISTORY_LEN = 10

def tts_worker():
    asyncio.set_event_loop(asyncio.new_event_loop())
    loop = asyncio.get_event_loop()
    while True:
        text = tts_queue.get()
        if text is None:
            break
        if text.strip():
            try:
                loop.run_until_complete(speak_stream(text))
            except RuntimeError as e:
                print(f"[TTS Error] {e}")

Thread(target=tts_worker, daemon=True).start()

async def summarize_old_history(old_history):
    summary_prompt = "ë‹¤ìŒ ëŒ€í™”ë¥¼ ìš”ì•½í•´ì¤˜:\n"
    for msg in old_history:
        summary_prompt += f"{msg['role']}: {msg['content']}\n"

    result = await client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "ë‹¤ìŒ ëŒ€í™” ë‚´ìš©ì„ ê°„ê²°í•˜ê³  í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜."},
            {"role": "user", "content": summary_prompt}
        ]
    )
    return result.choices[0].message.content.strip()

async def query_gpt_stream(prompt):
    global summary, history

    print("ğŸ§  GPT ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘")

    history.append({"role": "user", "content": prompt})

    # ì˜¤ë˜ëœ íˆìŠ¤í† ë¦¬ ìš”ì•½
    if len(history) > MAX_HISTORY_LEN:
        old = history[:-MAX_HISTORY_LEN]
        history = history[-MAX_HISTORY_LEN:]
        summary = await summarize_old_history(old)

    # GPT ë©”ì‹œì§€ êµ¬ì„±
    messages = [{"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ ë¹„ì„œì•¼. ì§§ê³  ê°„ë‹¨í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜"}]
    if summary:
        messages.append({"role": "system", "content": f"ì§€ê¸ˆê¹Œì§€ì˜ ìš”ì•½: {summary}"})
    messages.extend(history)

    stream = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=messages,
        stream=True,
    )

    buffer = ""
    async for chunk in stream:
        if chunk.choices[0].delta.content:
            piece = chunk.choices[0].delta.content
            print(piece, end="", flush=True)
            buffer += piece

            if any(p in piece for p in ".!?"):
                tts_queue.put(buffer.strip())
                buffer = ""

    if buffer.strip():
        tts_queue.put(buffer.strip())

    print("\nğŸ§  GPT ì‘ë‹µ ì™„ë£Œ")

    history.append({"role": "assistant", "content": buffer.strip()})

def shutdown_tts():
    tts_queue.put(None)
