import asyncio
import threading
import os
from queue import Queue
from openai import AsyncOpenAI
from dotenv import load_dotenv
from tts import google_tts_stream_from_gpt_chunks
from state import is_tts_playing

load_dotenv()
gpt_client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
tts_queue = Queue()

# ì „ì—­ íˆìŠ¤í† ë¦¬
history = [{"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ í•œêµ­ì–´ ë¹„ì„œì•¼. ì§§ê³  ê°„ë‹¨í•˜ê²Œ ëŒ€ë‹µí•´ì¤˜."}]
MAX_HISTORY_LEN = 10

# ë°±ê·¸ë¼ìš´ë“œ TTS ì“°ë ˆë“œ ì‹¤í–‰

def tts_worker():
    while True:
        text = tts_queue.get()
        if text is None:
            break
        asyncio.run(google_tts_stream_from_gpt_chunks(text))

threading.Thread(target=tts_worker, daemon=True).start()

# GPT ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ í›„ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ TTS íì— ì „ë‹¬
async def query_gpt_stream(prompt: str):
    global history

    history.append({"role": "user", "content": prompt})

    while len(history) > MAX_HISTORY_LEN * 2 + 1:
        del history[1:3]

    stream = await gpt_client.chat.completions.create(
        model="gpt-4o",
        messages=history,
        stream=True,
    )

    print("\nğŸ§  GPT ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì‹œì‘")
    full_response = ""
    async for chunk in stream:
        if chunk.choices[0].delta.content:
            piece = chunk.choices[0].delta.content
            print(piece, end="", flush=True)
            full_response += piece

    print("\nğŸ§  GPT ì‘ë‹µ ì™„ë£Œ")

    if full_response.strip():
        history.append({"role": "assistant", "content": full_response.strip()})
        tts_queue.put(full_response.strip())